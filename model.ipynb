{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tqdm\n",
    "import operator\n",
    "import lightgbm as lg\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data \n",
    "queries = {}\n",
    "with open('./features/norm_q.txt') as fin:\n",
    "    lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        if line[0] == '':\n",
    "            line.pop(0)\n",
    "        queries[line[0]] = line[1]\n",
    "\n",
    "titles= {}\n",
    "with open(\"./features/norm_tits.txt\" ,'r', encoding='utf-8') as fin:\n",
    "    for line in fin.readlines():\n",
    "        line=line.split('\\t')\n",
    "        titles[line[0]]= line[1][:-1]\n",
    "\n",
    "train=[]\n",
    "with open(\"./initial_data/train.marks.tsv/train.marks.tsv\", 'r') as fin:\n",
    "    for line in fin.readlines():\n",
    "        line=line[:-1].split('\\t')\n",
    "        train.append([line[0],line[1], line[2]])\n",
    "\n",
    "\n",
    "                \n",
    "test=[]\n",
    "with open(\"./initial_data/sample.csv/sample.csv\", 'r') as fin:\n",
    "    fin.readline()\n",
    "    for line in fin.readlines():\n",
    "        line=line[:-1].split(',')\n",
    "        test.append([line[0],line[1],-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ptfbm.py\n",
    "texttf = {}\n",
    "tffiles = os.listdir('./features/tf')\n",
    "for file in tffiles:\n",
    "    with open('./features/tf/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        texttf[(line[0], line[1])] = np.float64(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hostdict = {}\n",
    "with open('./initial_data/url.data/url.data') as fin:\n",
    "    lines = fin.readlines()\n",
    "for line in lines:\n",
    "    line = line[:-1].split('\\t')\n",
    "    if line[1][:7] == 'http://':\n",
    "        line[1] = line[1][7:]\n",
    "    if line[1][:4] == 'www.':\n",
    "        line[1] = line[1][4:]\n",
    "    hostdict[line[0]] = line[1].split('/')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all.java\n",
    "hostfiles = os.listdir('./features/DDF')\n",
    "hf = {}\n",
    "qhf = {}\n",
    "c = 0\n",
    "for file in hostfiles:\n",
    "    with open('./features/DDF/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        line.pop()\n",
    "        if file[0] == 'Q':\n",
    "            q = line.pop(0)\n",
    "            h = line.pop(0)\n",
    "            qhf[(q,h)] = np.array(line, dtype = np.float64)\n",
    "            c+=1\n",
    "        else:\n",
    "            h = line.pop(0)\n",
    "            hf[h] = np.array(line, dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allurl.java\n",
    "urlfiles = os.listdir('./features/UDDF')\n",
    "uf = {}\n",
    "quf = {}\n",
    "for file in urlfiles:\n",
    "    with open('./features/UDDF/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        line.pop()\n",
    "        if file[1] == 'Q':\n",
    "            q = line.pop(0)\n",
    "            u = line.pop(0)\n",
    "            quf[(q,u)] = np.array(line, dtype = np.float64)\n",
    "        else:\n",
    "            u = line.pop(0)\n",
    "            uf[u] = np.array(line, dtype = np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#simdoc.py\n",
    "similars = {}\n",
    "with open('./features/oldsimdoc.txt', 'r') as fin:\n",
    "    lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        spl = line[:-2].split('\\t')\n",
    "        if len(spl) == 1:\n",
    "            continue\n",
    "        tmp = spl[1].split(' ')\n",
    "        for i in range(13):\n",
    "            tmp.pop()\n",
    "        similars[spl[0]] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simdoc.py\n",
    "file =open(\"./features/dvs.txt\" ,'r', encoding='utf-8')\n",
    "dvs= {}\n",
    "for line in file.readlines():\n",
    "    l=line.split('\\t')\n",
    "    dvs[(l[0], l[1])]= np.array(l[2][:-1], dtype = np.float64)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ptfbm_titles.py\n",
    "file =open(\"./features/tf23.txt\" ,'r', encoding='utf-8')\n",
    "ttit1= {}\n",
    "for line in file.readlines():\n",
    "    l=line.split('\\t')\n",
    "    ttit1[(l[0], l[1])]= np.array(l[2][:-1], dtype = np.float64)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ptfbm_titles.py\n",
    "file =open(\"./features/tf39.txt\" ,'r', encoding='utf-8')\n",
    "ttit3= {}\n",
    "for line in file.readlines():\n",
    "    l=line.split('\\t')\n",
    "    ttit3[(l[0], l[1])]= np.array(l[2][:-1], dtype = np.float64)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DBN.java\n",
    "file =open(\"./features/DBN/part-r-00000\" ,'r', encoding='utf-8')\n",
    "dbndoc = {}\n",
    "for line in file.readlines():\n",
    "    l=line[:-1].split('\\t')\n",
    "    k = l[0]\n",
    "    l.pop(0)\n",
    "    dbndoc[k]= np.array(l, dtype = np.float64)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ptfbm.py\n",
    "ltf = {}\n",
    "ltffiles = os.listdir('./features/ltf')\n",
    "for file in ltffiles:\n",
    "    with open('./features/ltf/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        ltf[(line[0], line[1])] = np.float64(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allq.java\n",
    "file =open(\"./features/QF/part-r-00000\" ,'r', encoding='utf-8')\n",
    "qf = {}\n",
    "for line in file.readlines():\n",
    "    l=line[:-1].split('\\t')\n",
    "    k = l[0]\n",
    "    l.pop(0)\n",
    "    qf[k]= np.array(l, dtype = np.float64)\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pas.py\n",
    "pas = {}\n",
    "pasfiles = os.listdir('./features/pas')\n",
    "for file in pasfiles:\n",
    "    with open('./features/pas/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        if len(line) > 1:\n",
    "            pas[(file[:-4], line[0])] = np.log(1 + np.float64(line[1]))\n",
    "#ptfbm.py\n",
    "newbm = {}\n",
    "newbmfiles = os.listdir('./features/newbm')\n",
    "for file in newbmfiles:\n",
    "    with open('./features/newbm/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        if len(line) > 1:\n",
    "            newbm[(file[:-4], line[0])] = np.log(1+ np.float64(line[1]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simdoc.py\n",
    "muse = {}\n",
    "musefiles = os.listdir('./features/muse/muse')\n",
    "for file in musefiles:\n",
    "    with open('./features/muse/muse/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        if len(line) > 1:\n",
    "            muse[(line[0], line[1])] = np.float64(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simdoc.py\n",
    "luse = {}\n",
    "with open('./features/luse.txt') as fin:\n",
    "    lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        luse[(line[0], line[1])] = np.float64(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simdoc.py\n",
    "quse = {}\n",
    "with open('./features/quse.txt') as fin:\n",
    "    lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        quse[(line[0], line[1])] = np.float64(line[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pasT.py\n",
    "past = {}\n",
    "pastfiles = os.listdir('./features/pasT')\n",
    "for file in pastfiles:\n",
    "    with open('./features/pasT/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        if len(line) > 1:\n",
    "            past[(file[:-4], line[0])] = np.log(1+ np.float64(line[1]))\n",
    "            \n",
    "#pas.py\n",
    "pas3 = {}\n",
    "pas3files = os.listdir('./features/pas3')\n",
    "for file in pas3files:\n",
    "    with open('./features/pas3/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        if len(line) > 1:\n",
    "            pas3[(file[:-4], line[0])] = np.log(1+ np.float64(line[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simdoc.py\n",
    "trft = {}\n",
    "trftfiles = os.listdir('./features/trft')\n",
    "for file in pastfiles:\n",
    "    with open('./features/trft/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        if len(line) > 1:\n",
    "            trft[(file[:-4], line[0])] = np.float64(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simdoc.py\n",
    "ft = {}\n",
    "ftfiles = os.listdir('./features/ftsim/ftsim')\n",
    "for file in pas3files:\n",
    "    with open('./features/ftsim/ftsim/' + file) as fin:\n",
    "        lines = fin.readlines()\n",
    "    for line in lines:\n",
    "        line = line[:-1].split('\\t')\n",
    "        if len(line) > 1:\n",
    "            ft[(file[:-4], line[0])] = np.float64(line[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getdata(cat):\n",
    "    trainx = []\n",
    "    trainy = []\n",
    "    qid_train = []\n",
    "    index = []\n",
    "    for entry in tqdm.tqdm(cat):\n",
    "        try:\n",
    "            try:\n",
    "                tempx = hf[hostdict[entry[1]]]\n",
    "            except:\n",
    "                temp = None\n",
    "    #             for q in similars[entry[0]]:\n",
    "    #                 if hostdict[entry[1]] in hf.keys():\n",
    "    #                     temp = hf[hostdict[entry[1]]]\n",
    "    #                     break\n",
    "                if temp is None:\n",
    "                    [temp] = [[0.0] * 13]\n",
    "                tempx = temp\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,qhf[(entry[0],hostdict[entry[1]])]))\n",
    "            except:\n",
    "                temp = None\n",
    "                for q in similars[entry[0]]:\n",
    "                    if (q,hostdict[entry[1]]) in qhf.keys():\n",
    "                        temp = qhf[(q,hostdict[entry[1]])]\n",
    "                        break\n",
    "                if temp is None:\n",
    "                    [temp] = [[0.0] * 43]\n",
    "                tempx = np.hstack((tempx,temp))\n",
    "\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,uf[entry[1]]))\n",
    "            except:\n",
    "                temp = None\n",
    "    #             if hostdict[entry[1]] in hf.keys():\n",
    "    #                 temp = hf[hostdict[entry[1]]]\n",
    "                for q in similars[entry[0]]:\n",
    "                    if entry[1] in uf.keys():\n",
    "                        temp = uf[entry[1]]\n",
    "                        break\n",
    "                if temp is None:\n",
    "                    [temp] = [[0.0] * 13]\n",
    "                tempx = np.hstack((tempx,temp))\n",
    "\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,quf[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                temp = None\n",
    "    #             if (entry[0],hostdict[entry[1]]) in qhf.keys():\n",
    "    #                 temp = qhf[(entry[0],hostdict[entry[1]])]\n",
    "                for q in similars[entry[0]]:\n",
    "                    if (q,entry[1]) in quf.keys():\n",
    "                        temp = quf[(q,entry[1])]\n",
    "                        break\n",
    "                if temp is None:\n",
    "                    [temp] = [[0.0] * 43]\n",
    "                tempx = np.hstack((tempx,temp))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,texttf[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,dvs[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,ttit1[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,ttit3[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,dbndoc[entry[1]]))\n",
    "            except:\n",
    "                temp = None\n",
    "                if temp is None:\n",
    "                    [temp] = [[0.0] * 3]\n",
    "                tempx = np.hstack((tempx,temp))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,ltf[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,qf[entry[0]]))\n",
    "            except:\n",
    "                temp = None\n",
    "                if temp is None:\n",
    "                    for q in similars[entry[0]]:\n",
    "                        if q in qf.keys():\n",
    "                            temp = qf[q]\n",
    "                            break\n",
    "                if temp is None:\n",
    "                    [temp] = [[0.0] * 23]\n",
    "                tempx = np.hstack((tempx,temp))\n",
    "\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,pas[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,newbm[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,trft[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,muse[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,past[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,pas3[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,ft[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            try:\n",
    "                tempx = np.hstack((tempx,quse[(entry[0],entry[1])]))\n",
    "            except:\n",
    "                tempx = np.hstack((tempx,np.array([0.0])))\n",
    "            trainx.append(tempx)\n",
    "            trainy.append(float(entry[2]))\n",
    "            qid_train.append(int(entry[0]))\n",
    "            index.append((entry[0], entry[1]))\n",
    "        except:\n",
    "            continue\n",
    "    Xtrain = np.row_stack([row for row in trainx])\n",
    "    Ytrain = np.row_stack([row for row in trainy])\n",
    "    return Xtrain, Ytrain, qid_train, index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain = np.load('./ready-to-use-features/Xtrain.npy')\n",
    "Ytrain = np.load('./ready-to-use-features/Ytrain.npy')\n",
    "Xtest = np.load('./ready-to-use-features/Xtest.npy')\n",
    "qqg = np.load('./ready-to-use-features/qqg.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202079/202079 [00:31<00:00, 6421.21it/s]\n"
     ]
    }
   ],
   "source": [
    "Xtrain, Ytrain, qid_train, tindex = getdata(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "qqg = np.unique(qid_train, return_counts=True)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 403971/403971 [01:10<00:00, 5760.50it/s]\n"
     ]
    }
   ],
   "source": [
    "Xtest,Ytest, _ , index = getdata(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgrank = lg.LGBMRanker(objective='lambdarank', max_depth=12, n_estimators= 1000, subsample=0.8, learning_rate=0.01, num_leaves=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25min 25s, sys: 6.1 s, total: 25min 31s\n",
      "Wall time: 4min 2s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMRanker(learning_rate=0.01, max_depth=12, n_estimators=1000, num_leaves=64,\n",
       "           objective='lambdarank', subsample=0.8)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "lgrank.fit(Xtrain,Ytrain.ravel(),group=qqg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 10s, sys: 104 ms, total: 1min 10s\n",
      "Wall time: 10.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cres = lgrank.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1074, 1180, 1237,  525,  630,  677,  789,  696,  980,    0,  485,\n",
       "          0,  233,  502,  745,  200,   57,  117,   96,  249,   78,  185,\n",
       "          0,   90,    0,  150,   95,   97,   60,   62,   80,   42,   61,\n",
       "         43,   78, 1359, 1005,  651,  443,  358,  384,  385,  358,  449,\n",
       "        316,  371,  107,  106,   80,   72,   50,   45,   70,   98,  147,\n",
       "        300,  275,  360,  169,   61,  106,  101,  114,   44,  177,    0,\n",
       "         56,    0,  330,  284,  510,   96,   30,   65,   72,  124,   39,\n",
       "         96,    0,   31,    0,  158,  198,  276,  203,  163,  142,  160,\n",
       "        155,  184,  316,  774,  455,  431,  328,  292,  201,  220,  230,\n",
       "        118,   62,  236,  122,  111,  143,  125,  104,   89,  121,  121,\n",
       "        152, 3015, 1829, 1320, 1810, 1767,  713,  949, 1282, 1971,  515,\n",
       "        507,  294,  612,   54,    0,    0,    0,    0,    0,    0,    0,\n",
       "          0,    0,  806,  842,  903,  326,  317,    0,    0,    0, 1411,\n",
       "        569, 2295, 1164, 2341, 1577, 1452, 4082], dtype=int32)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgrank.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "qdres = {}\n",
    "for i, dkey in enumerate(index):\n",
    "    qdres[tuple(dkey)] = cres[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403972\n"
     ]
    }
   ],
   "source": [
    "sqd = {}\n",
    "qdres = {}\n",
    "with open('./initial_data/sample.csv/sample.csv', 'r') as fin:\n",
    "    sample = fin.readlines()\n",
    "    print(len(sample))\n",
    "    for i in range(1,len(sample)):\n",
    "        sample[i] = sample[i][:-1]\n",
    "        tr = sample[i].split(',')\n",
    "        if tr[0] not in sqd.keys():\n",
    "            sqd[tr[0]] = []\n",
    "        else:\n",
    "            sqd[tr[0]].append(tr[1])\n",
    "        qdres[tuple(tr)] = cres[i-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for key in sqd:\n",
    "    res = {}\n",
    "    for doc in sqd[key]:\n",
    "        try:\n",
    "            res[doc] = qdres[(key,doc)]\n",
    "        except:\n",
    "            continue\n",
    "    sortres = sorted(res.items(), key = operator.itemgetter(1), reverse = True)\n",
    "    for i in range(len(sortres)):\n",
    "        results.append([key,sortres[i][0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submit.csv', 'w') as fout:\n",
    "    fout.write('QueryId,DocumentId\\n')\n",
    "    for result in results:\n",
    "        fout.write(result[0] + ',' + result[1]+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get feature importance\n",
    "featslist = []\n",
    "with open('feats.txt') as fin:\n",
    "    for line in fin.readlines():\n",
    "        featslist.append(line[line.find(' ') + 1:-1])\n",
    "feats = {}\n",
    "for i, fimp in enumerate(lgrank.feature_importances_):\n",
    "    feats[featslist[i]] = fimp\n",
    "sfeats = sorted(feats.items(), key = operator.itemgetter(1), reverse = True)\n",
    "with open('featsimp.txt','w') as fout:\n",
    "    for el in sfeats:\n",
    "        fout.write(el[0] + '\\t' + str(el[1])+'\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
